import sklearn.metrics
from sklearn import datasets
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import math
import numpy as np
import pandas as pd


class Node:
    "Decision tree node"

    def __init__(self, entropy, num_samples, num_samples_per_class, predicted_class, num_errors, alpha=float("inf")):
        self.entropy = entropy  # the entropy of current node
        self.num_samples = num_samples  # current instance
        # the instance per class after split
        self.num_samples_per_class = num_samples_per_class
        self.predicted_class = predicted_class  # the majority class of the split group
        self.feature_index = 0  # the feature index we used to split the node
        self.threshold = 0  # for binary split (a >= ?)
        self.left = None  # left child node
        self.right = None  # right child node
        self.num_errors = num_errors  # error after cut
        self.alpha = alpha  # each node alpha

# Y = Target


class DecisionTreeClassifier:
    def __init__(self, max_depth=4):
        self.max_depth = max_depth

    def _entropy(self, sample_y, n_classes):
        entropy = .0
        ###
        i = np.count_nonzero(sample_y == 1)
        p = sample_y.size - i
        pi = float((i / len(sample_y)))

        npi = float(p / len(sample_y))

        if i == 0:
            entropy = - (npi * math.log((npi), 2))
        elif p == 0:
            entropy = - (pi * math.log((pi), 2))
        else:
            entropy = - (pi * math.log(pi, 2)) - (npi * math.log(npi, 2))

        #entropy = -((p / sample_y.size) * math.log2(p / sample_y.size)) - ((n / sample_y.size) * math.log2(n / sample_y.size))
        # TODO: calculate the entropy of sample_y and return it
        # sample_y
        # entropy = -sum(pi * log2(pi))

        ###
        return entropy

    def _feature_split(self, X, y, n_classes):
        # Returns:
        #  best_idx: Index of the feature for best split, or None if no split is found.
        #  best_thr: Threshold to use for the split, or None if no split is found.
        m = y.size
        if m <= 1:
            return None, None

        # Entropy of current node.

        best_criterion = self._entropy(y, n_classes)

        best_idx, best_thr = None, None
        # TODO
        Inf_gain = .0
        # feature
        for i in range(np.size(X, 1)):
            # take each row_value as thr
            for j in range(len(X[:, i])):
                # To count the entropy
                left = []
                right = []
                for k in range(len(X[:, i])):
                    tmp_thr = X[j, i]
                    if (X[k, i] >= tmp_thr):
                        # just count the number instead of classify
                        right.append(y[k])
                        # split to right
                    elif (X[k, i] < tmp_thr):
                        left.append(y[k])
                        # split to left

                left = np.array(left)
                right = np.array(right)
                all_size = (right.size+left.size)
                Info_en = .0
                # weight
                if left.size == 0:
                    Info_en = self._entropy(right, n_classes)
                elif right.size == 0:
                    Info_en = self._entropy(left, n_classes)
                else:
                    Info_en = (((left.size/all_size)*self._entropy(left, n_classes)) +
                               ((right.size/all_size)*self._entropy(right, n_classes)))

                Gain = best_criterion - Info_en
                if Gain > Inf_gain:
                    Inf_gain = Gain
                    best_idx = i
                    best_thr = tmp_thr

        # TODO: find the best split, loop through all the features, and consider all the
        # midpoints between adjacent training samples as possible thresholds.
        # Compute the Entropy impurity of the split generated by that particular feature/threshold
        # pair, and return the pair with smallest impurity.

        return best_idx, best_thr

    def _build_tree(self, X, y, depth=0):
        num_samples_per_class = [np.sum(y == i)
                                 for i in range(self.n_classes_)]
        predicted_class = np.argmax(num_samples_per_class)
        correct_label_num = num_samples_per_class[predicted_class]
        num_errors = y.size - correct_label_num
        node = Node(
            entropy=self._entropy(y, self.n_classes_),
            num_samples=y.size,
            num_samples_per_class=num_samples_per_class,
            predicted_class=predicted_class,
            num_errors=num_errors
        )

        if depth < self.max_depth:
            idx, thr = self._feature_split(X, y, self.n_classes_)
            if idx is not None:
                # TODO
                node.feature_index = idx
                node.threshold = thr
                left_X = []
                right_X = []
                left_y = []
                right_y = []
                for i in range(len(X[:, idx])):
                    if(X[i, idx] >= thr):
                        right_X.append(X[i, :])
                        right_y.append(y[i])

                    elif(X[i, idx] < thr):
                        left_X.append(X[i, :])
                        left_y.append(y[i])

                left_X = np.array(left_X)
                left_y = np.array(left_y)
                right_X = np.array(right_X)
                right_y = np.array(right_y)
                # left_X = np.delete(left_X, idx, axis=1)
                # right_X = np.delete(right_X, idx, axis=1)

                node.right = self._build_tree(
                    right_X, right_y, depth=depth + 1)
                node.left = self._build_tree(left_X, left_y, depth=depth + 1)
                # TODO: Split the tree recursively according index and threshold until maximum depth is reached.

                pass
        return node

    def fit(self, X, Y):
        # TODO
        self.n_classes_ = 2
        self.tree_ = self._build_tree(X, Y)
        # TODO
        # Fits to the given training data
        pass

    def predict(self, X):
        pred = []
        # TODO
        for i in range(np.size(X, 0)):
            tmp_node = self.tree_
            while(True):
                if tmp_node.left == None and tmp_node.right == None:
                    pred.append(tmp_node.predicted_class)
                    break
                else:
                    if X[i][tmp_node.feature_index] < tmp_node.threshold:
                        tmp_node = tmp_node.left
                    elif X[i][tmp_node.feature_index] >= tmp_node.threshold:
                        tmp_node = tmp_node.right
        # TODO: predict the label of data
        return pred

    def _find_leaves(self, root):
        # TODO
        leaves_number = 0
        stack = []
        stack.append(root)

        while(True):
            if len(stack) == 0:
                break

            tmp = stack.pop()
            if tmp.left != None:
                stack.append(tmp.left)

            if tmp.right != None:
                stack.append(tmp.right)

            if tmp.left == None and tmp.right == None:
                leaves_number += 1

        return leaves_number
        # TODO
        # find each node child leaves number
        pass

    def _error_before_cut(self, root):
        # TODO
        error_before_cut_num = 0
        current_node = root
        stack = []
        stack.append(current_node)
        while (True):
            if len(stack) == 0:
                break
            tmp_node = stack.pop()

            if (tmp_node.left == None and tmp_node.right == None):
                error_before_cut_num += tmp_node.num_errors

            elif (tmp_node.left != None and tmp_node.right != None):
                stack.append(tmp_node.left)
                stack.append(tmp_node.right)

        return error_before_cut_num

        # TODO
        # return error before post-pruning
        pass

    def _compute_alpha(self, root):

        # TODO
        stack = []
        stack.append(root)

        while(True):
            if len(stack) == 0:
                break

            tmp_node = stack.pop()

            if tmp_node.left != None or tmp_node.right != None:
                stack.append(tmp_node.left)
                stack.append(tmp_node.right)
                tmp_node.alpha = (
                    (tmp_node.num_errors - self._error_before_cut(tmp_node)) / (self._find_leaves(tmp_node) - 1))
            else:
                tmp_node.alpha = float("inf")

        # TODO
        # Compute each node alpha
        # alpha = (error after cut - error before cut) / (leaves been cut - 1)
        pass

    def _find_min_alpha(self, root):
        MinAlpha = float("inf")
        # TODO
        min_node = None
        stack = []
        stack.append(root)
        while (True):
            if len(stack) == 0:
                break
            tmp_node = stack.pop()

            if (tmp_node.left != None and tmp_node.right != None):
                stack.append(tmp_node.left)
                stack.append(tmp_node.right)
            if (MinAlpha > tmp_node.alpha):
                MinAlpha = tmp_node.alpha
                min_node = tmp_node

        return min_node
        # TODO
        # Search the Decision tree which have minimum alpha's node
        pass

    def _prune(self):
        self._compute_alpha(self.tree_)
        cut_node = self._find_min_alpha(self.tree_)
        # TODO
        cut_node.left = None
        cut_node.right = None
        # prune the decision tree with minimum alpha node
        pass


# the data split into test and train
def load_train_test_data(test_ratio=.3, random_state=1):
    df = pd.read_csv('.\heart_dataset.csv')
    X = df.drop(columns=['target'])  # remove the target column
    X = np.array(X.values)  # take the value only
    y = df['target']
    y = np.array(y.values)
    # get the train & test data split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_ratio, random_state=random_state, stratify=y)
    return X_train, X_test, y_train, y_test


def accuracy_report(X_train_scale, y_train, X_test_scale, y_test, max_depth=7):
    tree = DecisionTreeClassifier(max_depth=max_depth)
    tree.fit(X_train_scale, y_train)
    pred = tree.predict(X_train_scale)

    print(" tree train accuracy: %f"
          % (sklearn.metrics.accuracy_score(y_train, pred)))
    pred = tree.predict(X_test_scale)
    print(" tree test accuracy: %f"
          % (sklearn.metrics.accuracy_score(y_test, pred)))

    for i in range(10):
        print("=============Cut=============")
        tree._prune()
        pred = tree.predict(X_train_scale)
        print(" tree train accuracy: %f"
              % (sklearn.metrics.accuracy_score(y_train, pred)))
        pred = tree.predict(X_test_scale)
        print(" tree test accuracy: %f"
              % (sklearn.metrics.accuracy_score(y_test, pred)))


def main():
    X_train, X_test, y_train, y_test = load_train_test_data(
        test_ratio=.3, random_state=1)
    accuracy_report(X_train, y_train, X_test, y_test, max_depth=8)


if __name__ == "__main__":
    main()
